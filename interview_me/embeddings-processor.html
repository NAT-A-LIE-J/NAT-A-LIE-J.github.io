<!DOCTYPE html>
<html>
<head>
    <title>Document Processor</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/3.11.174/pdf.min.js"></script>
</head>
<body>
    <h2>Interview Bot Document Processor</h2>
    <input type="file" id="pdfInput" accept=".pdf" multiple>
    <button onclick="processDocuments()">Process Documents</button>
    <div id="status"></div>

    <script>
    async function processDocuments() {
        const files = document.getElementById('pdfInput').files;
        const status = document.getElementById('status');
        const chunks = [];

        for (const file of files) {
            status.textContent = `Processing ${file.name}...`;
            
            // Extract text from PDF
            const arrayBuffer = await file.arrayBuffer();
            const pdf = await pdfjsLib.getDocument(arrayBuffer).promise;
            
            // Process each page
            for (let i = 1; i <= pdf.numPages; i++) {
                const page = await pdf.getPage(i);
                const textContent = await page.getTextContent();
                const pageText = textContent.items.map(item => item.str).join(' ');
                
                // Split page into chunks (roughly 300 tokens â‰ˆ 1200 chars)
                const chunkSize = 1200;
                const overlap = 200;
                
                for (let j = 0; j < pageText.length; j += chunkSize - overlap) {
                    const chunk = pageText.slice(j, j + chunkSize);
                    if (chunk.trim().length > 100) { // Skip very small chunks
                        chunks.push({
                            text: chunk,
                            source: file.name,
                            page: i,
                            chunkIndex: chunks.length
                        });
                    }
                }
            }
        }

        // Generate embeddings for each chunk
        status.textContent = 'Generating embeddings...';
        const embeddingsData = [];
        
        for (const chunk of chunks) {
            const response = await fetch('https://interview-dh6kw2zz1-natalie-lam-johnsons-projects.vercel.app/api/embed', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text: chunk.text })
            });
            
            const { embedding } = await response.json();
            embeddingsData.push({
                ...chunk,
                embedding: embedding
            });
            
            status.textContent = `Processed ${embeddingsData.length}/${chunks.length} chunks`;
        }

        // Store in IndexedDB
        await storeEmbeddings(embeddingsData);
        status.textContent = 'Complete! Embeddings stored in browser.';
    }

    async function storeEmbeddings(data) {
        const db = await openDB();
        const transaction = db.transaction(['embeddings'], 'readwrite');
        const store = transaction.objectStore('embeddings');
        
        // Clear existing data
        await store.clear();
        
        // Store new embeddings
        for (const item of data) {
            await store.add(item);
        }
    }

    function openDB() {
        return new Promise((resolve, reject) => {
            const request = indexedDB.open('InterviewBotDB', 1);
            
            request.onerror = () => reject(request.error);
            request.onsuccess = () => resolve(request.result);
            
            request.onupgradeneeded = (event) => {
                const db = event.target.result;
                if (!db.objectStoreNames.contains('embeddings')) {
                    db.createObjectStore('embeddings', { keyPath: 'chunkIndex' });
                }
            };
        });
    }
    </script>
</body>
</html>